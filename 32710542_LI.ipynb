{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 for FIT5212, Semester 1\n",
    "\n",
    "**Student Name:**  Han Li\n",
    "\n",
    "**Student ID:**  32710542"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "##### Below block is for loading all libraries required for the project and preliminary set up including device and seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For data loading and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For data visulisation\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "\n",
    "#For preprocssing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import nltk\n",
    "from nltk import PorterStemmer,WordNetLemmatizer,wordpunct_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re\n",
    "\n",
    "#For Modelling\n",
    "#pip install xgboost\n",
    "#pip install lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "#import lightgbm as lgb\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#For performance metrics, data spliting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (confusion_matrix,f1_score,ConfusionMatrixDisplay,\n",
    "                             precision_score,accuracy_score,\n",
    "                             recall_score,matthews_corrcoef,precision_recall_curve)\n",
    "\n",
    "#For Model tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV,train_test_split\n",
    "\n",
    "#Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import random\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is to train a statistic NLP model for classify artical class by either Abstract or Titles. To do so I will be applying 2 different preprocessing configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reprodiction\n",
    "SEED = 23\n",
    "def seeding(SEED = SEED):\n",
    "    \"\"\"SEED: int number define by variable SEED\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "seeding() \n",
    "\n",
    "# Setting up cuda for Colab GPU runtime and mps for ARM enviroment\n",
    "# The code will be test under macos arm with mps support and Colab GPU runtime with cuda support\n",
    "device = torch.device('cuda' if \n",
    "torch.cuda.is_available() else 'mps')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assert train.csv and test.csv are in working directory\n",
    "train_dir = (os.getcwd() +'/train.csv' if 'train.csv' in os.listdir() else print('training set not in working directory'))\n",
    "test_dir = (os.getcwd() +'/test.csv' if 'test.csv' in os.listdir() else print('testing set not in working directory'))\n",
    "\n",
    "#Load datasets\n",
    "df_train = pd.read_csv(train_dir)\n",
    "df_test = pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>InformationTheory</th>\n",
       "      <th>ComputationalLinguistics</th>\n",
       "      <th>ComputerVision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>GRADE-AO: Towards Near-Optimal Spatially-Coupl...</td>\n",
       "      <td>Spatially-coupled (SC) codes known for their...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14713</th>\n",
       "      <td>Neural Fields as Learnable Kernels for 3D Reco...</td>\n",
       "      <td>We present Neural Kernel Fields: a novel met...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>Investigations on $c$-Boomerang Uniformity and...</td>\n",
       "      <td>We defined in~citeEFRST20 a new multiplicati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17692</th>\n",
       "      <td>Linear Adversarial Concept Erasure</td>\n",
       "      <td>Modern neural models trained on textual data...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>Parsing Free Word-Order Languages in Polynomia...</td>\n",
       "      <td>We present a parsing algorithm with polynomi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "17289  GRADE-AO: Towards Near-Optimal Spatially-Coupl...   \n",
       "14713  Neural Fields as Learnable Kernels for 3D Reco...   \n",
       "3532   Investigations on $c$-Boomerang Uniformity and...   \n",
       "17692                 Linear Adversarial Concept Erasure   \n",
       "9882   Parsing Free Word-Order Languages in Polynomia...   \n",
       "\n",
       "                                                abstract  InformationTheory  \\\n",
       "17289    Spatially-coupled (SC) codes known for their...                  1   \n",
       "14713    We present Neural Kernel Fields: a novel met...                  0   \n",
       "3532     We defined in~citeEFRST20 a new multiplicati...                  1   \n",
       "17692    Modern neural models trained on textual data...                  0   \n",
       "9882     We present a parsing algorithm with polynomi...                  0   \n",
       "\n",
       "       ComputationalLinguistics  ComputerVision  \n",
       "17289                         0               0  \n",
       "14713                         0               1  \n",
       "3532                          0               0  \n",
       "17692                         1               0  \n",
       "9882                          1               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect train and test data\n",
    "df_train.sample(10)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## For easy access, I will wrap all necessary steps for preprocessing in 1 single class\n",
    "#### Step 1: Training,Validation split (df_train_val_split)\n",
    "##### This is to split the entire training set into training and validation set basic on task requirement\n",
    "\n",
    "\n",
    "#### Step 2: preprocessing(preprocess) \n",
    "##### This is to preprocess the data using 2 different method\n",
    "##### Method 1: Text to be lower, remove stopword, paranthesis and other special charaters,spaces and apply porter stemmer and tfidf vectorizer\n",
    "##### Method 2: Text to be lower, remove special charaters,spaces and apply lemmatizer and countvectorizer\n",
    "\n",
    "#### Step 3:Clean(clean) \n",
    "##### This is to combine the above method and apply the cleaning to each input(text) of the datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocesser:\n",
    "    \"\"\"\n",
    "    How to use:\n",
    "    Initialize preprocesser \n",
    "    e.g. prep = preporcesser()\n",
    "\n",
    "    Obtain X,y for training and validation set using only the clean function \n",
    "    e.g. X_train,X_val,y_train,y_val = prep.clean(task = 'InformationTheory',size = 'sample',\n",
    "                                                input = 'abstract',method = 2)\n",
    "    \"\"\"\n",
    "\n",
    "    class LemmaTokenizer(object):\n",
    "        def __init__(self):\n",
    "            self.wnl = WordNetLemmatizer()\n",
    "\n",
    "        def __call__(self, doc):\n",
    "            return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "    class SteamTokenizer(object):\n",
    "        def __init__(self):\n",
    "            self.ps = PorterStemmer()\n",
    "\n",
    "        def __call__(self, doc):\n",
    "            return [self.ps.stem(t) for t in word_tokenize(doc)]\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.df = df_train\n",
    "        self.df_test = df_test\n",
    "        self.lemma = self.LemmaTokenizer()\n",
    "        self.steam  = self.SteamTokenizer()\n",
    "\n",
    "        self.stem_vectorizer = TfidfVectorizer(\n",
    "                                  tokenizer=self.steam)\n",
    "        self.LemmaTokenizer = CountVectorizer(\n",
    "            tokenizer=self.lemma\n",
    ")\n",
    "\n",
    "    def df_train_val_split(self, task, input, size):\n",
    "        \n",
    "        \"\"\"\n",
    "        task:Dependent variables can be choose from ['InformationTheory','ComputationalLinguistics','ComputerVision']\n",
    "\n",
    "        input:independent variable that can be choose from ['title','abstract']\n",
    "\n",
    "        size = select from ['full','sample'] to return either 10% or entire training set\n",
    "\n",
    "        df_train_1k, df_val_1k: The first 1000 sample of the df_train set(900 inputs), and split 10% as validation set(100 inputs)\n",
    "\n",
    "        df_train_all, df_val_all: The entire training data(112500 inputs) excluding 10% as validation set(12500 inputs)\n",
    "\n",
    "        Return: X_train,X_val,y_train,y_val the training and validation value as list for both X and y variables\n",
    "        \"\"\"\n",
    "        # Assert inputs meets function requirement\n",
    "        assert input in [\n",
    "            'title', 'abstract'], 'Please ensure input is choosen from title and abstract'\n",
    "        assert task in ['InformationTheory', 'ComputationalLinguistics',\n",
    "                        'ComputerVision'], 'Please ensure column name you wish to predict are correct'\n",
    "        assert size in ['full', 'sample'], 'choose only full or sample dataset'\n",
    "\n",
    "        if size == 'sample':\n",
    "            df_1k = self.df.sample(1000).reset_index(drop=True)\n",
    "            df_train_1k, df_val_1k = train_test_split(df_1k, test_size=.1)\n",
    "            X_train = df_train_1k[input].tolist()\n",
    "            X_val = df_val_1k[input].tolist()\n",
    "            y_train = df_train_1k[task].tolist()\n",
    "            y_val = df_val_1k[task].tolist()\n",
    "            \n",
    "            \n",
    "\n",
    "        elif size == 'full':\n",
    "            df_train_all, df_val_all = train_test_split(self.df, test_size=.1)\n",
    "            X_train = df_train_all[input].tolist()\n",
    "            X_val = df_val_all[input].tolist()\n",
    "            y_train = df_train_all[task].tolist()\n",
    "            y_val = df_val_all[task].tolist()\n",
    "\n",
    "        X_test = self.df_test[input].tolist()\n",
    "        y_test = self.df_test[task].tolist()\n",
    "        return X_train, X_val, X_test,y_train,y_val,y_test\n",
    "\n",
    "\n",
    "    def preprocess(self,text,method = 1):\n",
    "        \"\"\"\n",
    "        text :raw text from dataset input\n",
    "        method: int 1 or 2, refer to differetn preprocessing method\n",
    "        Method 1: Text to be lower, remove stopword, paranthesis and other special charaters,spaces and apply porter stemmer and tfidf vectorizer\n",
    "        Method 2:  Remove special charaters,spaces and apply lemmatizer and countvectorizer\n",
    "        \"\"\"\n",
    "        assert method in [1,2],'Please select 1 or 2 only'\n",
    "        STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "        \n",
    "        # Remove Special characters\n",
    "        text = re.sub(r'\\n','',text)\n",
    "        # Spacing and filters\n",
    "        text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "        text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
    "        text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
    "        text = text.strip() \n",
    "\n",
    "        if method == 1:\n",
    "            # Lower\n",
    "            text = text.lower()\n",
    "            # Remove stopwords\n",
    "            pattern = re.compile(r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*')\n",
    "            text = pattern.sub('', text)\n",
    "            # Remove words in paranthesis\n",
    "            text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def clean(self,task,size,input,method):\n",
    "        \"\"\"\n",
    "        Task,input,size = require argument for df_train_val_split\n",
    "        method = require argument ofr preprocess\n",
    "        \"\"\"\n",
    "        X_train, X_val, X_test,y_train,y_val,y_test= self.df_train_val_split(task,input,size)\n",
    "\n",
    "        if method == 1:\n",
    "            X_train = [self.preprocess(i,method =1 ) for i in X_train]\n",
    "            X_train = self.stem_vectorizer.fit_transform(X_train).astype(np.float64)\n",
    "            X_val = [self.preprocess(i,method =1) for i in X_val]\n",
    "            X_val = self.stem_vectorizer.transform(X_val).astype(np.float64)\n",
    "            X_test = [self.preprocess(i,method =1 ) for i in X_test]\n",
    "            X_test = self.stem_vectorizer.transform(X_test).astype(np.float64)\n",
    "        elif method == 2:\n",
    "            X_train = [self.preprocess(i,method =2 ) for i in X_train]\n",
    "            X_train = self.LemmaTokenizer.fit_transform(X_train).astype(np.float64)\n",
    "            X_val = [self.preprocess(i,method =2 ) for i in X_val]\n",
    "            X_val = self.LemmaTokenizer.transform(X_val).astype(np.float64)\n",
    "            X_test = [self.preprocess(i,method =2 ) for i in X_test]\n",
    "            X_test = self.LemmaTokenizer.transform(X_test).astype(np.float64)\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_val =np.asanyarray(y_val)\n",
    "        y_test=np.asanyarray(y_test)\n",
    "        return X_train, X_val, X_test,y_train,y_val,y_test\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1A: Statistical Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "##### All functions are wrapped in class training as above\n",
    "#### Step 1: Model Selection(model_selection)\n",
    "##### Using accuracy as metric, I will run a k fold cross validation for each model in the model dictionary, and return the best model base on the average accuracy over the k runs\n",
    "\n",
    "#### Step 2: Fine Tuning (fine_tuning) \n",
    "##### Using the best model from step 1, this function will conduct a grid serach to fine the best parameter of the best model. Returing a predition of y, i.e. y_pred\n",
    "\n",
    "#### Step 3:Drawing the Confusion Matrix and Precision recall curve (draw_metrix) \n",
    "##### This is draw the confusion matrix and PR Curve between y_pred and y_true. Also display the f1,precison,recall and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training:\n",
    "    \"\"\"\n",
    "    How to use:\n",
    "    Initialize training \n",
    "    e.g. train = training()\n",
    "\n",
    "    Using draw_metric it will automatecally draw the Confusion matrix and precision recall curve\n",
    "    your can also assign y_pred to it to obtain the prediction y\n",
    "    e.g. y_pred = tra.draw_metric(CV = 2,X = X_train,Y = y_train, X_val = X_val,y_val = y_val,\n",
    "                                i = i,m = m,t = t,s =s)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In here we also defined 2 dictionals to locate the require model and parameter as needed\n",
    "        \"\"\"\n",
    "        self.models = {\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'SVM':SVC(),\n",
    "    'BAGGING':BaggingClassifier()}\n",
    "        \n",
    "        self.param_grid = {\n",
    "        'XGBClassifier': {\n",
    "            'learning_rate': np.arange(0.001, 1, 0.05),\n",
    "            'subsample': np.arange(0, 1, 0.3),\n",
    "            'colsample_bytree': np.arange(0, 1, 0.3),\n",
    "            'learning_rate':np.arange(0.0001,0.1,0.05)\n",
    "        },\n",
    "        'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "        },\n",
    "         'BAGGING': {\n",
    "        'estimator': [DecisionTreeClassifier(), KNeighborsClassifier(), LogisticRegression()],\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_samples': [0.5, 0.75, 1.0],\n",
    "        'max_features': [0.5, 0.75, 1.0],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "        \n",
    "        }\n",
    "\n",
    "    def model_selection(self,CV,X_train,y_train):\n",
    "        \"\"\"\n",
    "        CV:number of Cross validation\n",
    "        NEED TO FIX\n",
    "        \"\"\"\n",
    "        cv_df = pd.DataFrame(index = range(CV *len(self.models)))\n",
    "        entries = []\n",
    "        for mod_name,model in self.models.items():\n",
    "            accs = cross_val_score(model,X_train,y_train,scoring = 'accuracy',cv = CV)\n",
    "            for cv_idx,acc in enumerate(accs):\n",
    "                entries.append((mod_name,cv_idx,acc))\n",
    "        cv_df  = pd.DataFrame(entries,columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "        best_model_name = cv_df.groupby('model_name')['accuracy'].mean().sort_values(ascending=False).index[0]\n",
    "        print(f\"The Most accuray model is {best_model_name}\")\n",
    "        return best_model_name\n",
    "    \n",
    "    def fine_tuning(self,CV,X_train,y_train,X_val,y_val,X_test,y_test):\n",
    "        \"\"\" \n",
    "        CV:number of Cross validation\n",
    "        X_train,y_train,X_val,y_val,X_test,y_test: tarining,validation and testing set respectively\n",
    "        \"\"\"\n",
    "        best_model_name = self.model_selection(CV,X_train,y_train)\n",
    "        randomized_scv = RandomizedSearchCV(\n",
    "            estimator=self.models[best_model_name],\n",
    "            param_distributions = self.param_grid[best_model_name],\n",
    "            n_iter = 20,\n",
    "            scoring= 'accuracy',\n",
    "            cv = CV,\n",
    "            random_state= 1,\n",
    "            n_jobs = -1\n",
    "        ).fit(X_val,y_val)\n",
    "        best_model = randomized_scv.best_estimator_\n",
    "        best_model.fit(X_val,y_val)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def draw_metric(self,CV,X_train,y_train,X_val,y_val,X_test,y_test ,i= None,m = None,t = None,s =None):\n",
    "        y_pred = self.fine_tuning(CV,X_train,y_train,X_val,y_val,X_test,y_test)\n",
    "        print(f\"The F1 Score for this setting is {f1_score(y_test,y_pred):.3f}\")\n",
    "        print(f\"The recall for this setting is {recall_score(y_test,y_pred):.3f}\")\n",
    "        print(f\"The Precision for this setting is {precision_score(y_test,y_pred):.3f}\")\n",
    "        print(f\"The accuracy for this setting is {accuracy_score(y_test,y_pred):.3f}\")\n",
    "        \n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        fig,(ax1,ax2) = plt.subplots(1,2,figsize = (15,5))\n",
    "        if i != None:\n",
    "            fig.suptitle(f\"Input: {i} Method: {m}, Task: {t}, size: {s}\")\n",
    "        ax1.imshow(cm,cmap = 'Spectral')\n",
    "        ax1.set_title('Confusion Matrix')\n",
    "        ax1.set_xlabel('Predicted Label')\n",
    "        ax1.set_ylabel('True Label')\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax1.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "        ax1.grid(False)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "        ax2.fill_between(recall, precision)\n",
    "        ax2.set_ylabel(\"Precision\")\n",
    "        ax2.set_xlabel(\"Recall\")\n",
    "        ax2.set_title(\"Precision-Recall curve\")\n",
    "        ax2.plot(recall,precision)\n",
    "        plt.show()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "ITER START\n",
      "Iter1 input: title, method: 1, task: InformationTheory, size: full\n"
     ]
    }
   ],
   "source": [
    "prep = preprocesser()\n",
    "tra = training()\n",
    "input = ['title', 'abstract']\n",
    "method = [1,2]\n",
    "task = ['InformationTheory', 'ComputationalLinguistics','ComputerVision']\n",
    "size = ['sample','full']\n",
    "Round = 0\n",
    "results_df = pd.DataFrame(columns=['input', 'method', 'task', 'size', 'f1_score'])\n",
    "\n",
    "for i in input:\n",
    "    for m in method:\n",
    "        for t in task:\n",
    "            for s in size:\n",
    "                Round+=1\n",
    "                X_train, X_val, X_test,y_train,y_val,y_test= prep.clean(input = i,method = m,task = t,size =s)\n",
    "                print('#######################################')\n",
    "                print('ITER START')\n",
    "                print(f\"Iter{Round} input: {i}, method: {m}, task: {t}, size: {s}\")\n",
    "                y_pred = tra.draw_metric(CV = 5,X_train = X_train,y_train = y_train, X_val = X_val,y_val = y_val,X_test=X_test,y_test = y_test,\n",
    "                                i = i,m = m,t = t,s =s)\n",
    "                print('ITER FINISH')\n",
    "                print('#######################################')\n",
    "                print('                                             ')\n",
    "                results_df = results_df.append({\"Iter\":Round,'input': i, 'method': m, 'task': t, 'size': s, \n",
    "                                                'f1_score': f1_score(y_test,y_pred), \"recall\":recall_score(y_test,y_pred),\n",
    "                                                'Precision':precision_score(y_test,y_pred),\n",
    "                                                'accuracy':accuracy_score(y_test,y_pred)}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>size</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Iter</th>\n",
       "      <th>recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abstract</td>\n",
       "      <td>2</td>\n",
       "      <td>ComputationalLinguistics</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.859183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abstract</td>\n",
       "      <td>1</td>\n",
       "      <td>ComputationalLinguistics</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.527888</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.435570</td>\n",
       "      <td>0.669863</td>\n",
       "      <td>0.854755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abstract</td>\n",
       "      <td>1</td>\n",
       "      <td>ComputerVision</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.968001</td>\n",
       "      <td>0.655916</td>\n",
       "      <td>0.814181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>1</td>\n",
       "      <td>ComputationalLinguistics</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.365038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.288302</td>\n",
       "      <td>0.497439</td>\n",
       "      <td>0.813019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title</td>\n",
       "      <td>2</td>\n",
       "      <td>ComputationalLinguistics</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.294291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.222684</td>\n",
       "      <td>0.433777</td>\n",
       "      <td>0.800897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title</td>\n",
       "      <td>1</td>\n",
       "      <td>ComputerVision</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.663888</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.627432</td>\n",
       "      <td>0.704841</td>\n",
       "      <td>0.781302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abstract</td>\n",
       "      <td>2</td>\n",
       "      <td>ComputerVision</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.725473</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.854317</td>\n",
       "      <td>0.630399</td>\n",
       "      <td>0.777427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>title</td>\n",
       "      <td>2</td>\n",
       "      <td>ComputerVision</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.655262</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.751407</td>\n",
       "      <td>0.580930</td>\n",
       "      <td>0.727831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abstract</td>\n",
       "      <td>2</td>\n",
       "      <td>InformationTheory</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.607278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.452648</td>\n",
       "      <td>0.922374</td>\n",
       "      <td>0.725230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abstract</td>\n",
       "      <td>1</td>\n",
       "      <td>InformationTheory</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.487480</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.323741</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.680505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>1</td>\n",
       "      <td>InformationTheory</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.421265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271494</td>\n",
       "      <td>0.939592</td>\n",
       "      <td>0.649895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title</td>\n",
       "      <td>2</td>\n",
       "      <td>InformationTheory</td>\n",
       "      <td>sample</td>\n",
       "      <td>0.403117</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.256280</td>\n",
       "      <td>0.943962</td>\n",
       "      <td>0.643806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input method                      task    size  f1_score  Iter  \\\n",
       "10  abstract      2  ComputationalLinguistics  sample  0.491200  11.0   \n",
       "7   abstract      1  ComputationalLinguistics  sample  0.527888   8.0   \n",
       "8   abstract      1            ComputerVision  sample  0.781971   9.0   \n",
       "1      title      1  ComputationalLinguistics  sample  0.365038   2.0   \n",
       "4      title      2  ComputationalLinguistics  sample  0.294291   5.0   \n",
       "2      title      1            ComputerVision  sample  0.663888   3.0   \n",
       "11  abstract      2            ComputerVision  sample  0.725473  12.0   \n",
       "5      title      2            ComputerVision  sample  0.655262   6.0   \n",
       "9   abstract      2         InformationTheory  sample  0.607278  10.0   \n",
       "6   abstract      1         InformationTheory  sample  0.487480   7.0   \n",
       "0      title      1         InformationTheory  sample  0.421265   1.0   \n",
       "3      title      2         InformationTheory  sample  0.403117   4.0   \n",
       "\n",
       "      recall  Precision  accuracy  \n",
       "10  0.364608   0.752451  0.859183  \n",
       "7   0.435570   0.669863  0.854755  \n",
       "8   0.968001   0.655916  0.814181  \n",
       "1   0.288302   0.497439  0.813019  \n",
       "4   0.222684   0.433777  0.800897  \n",
       "2   0.627432   0.704841  0.781302  \n",
       "11  0.854317   0.630399  0.777427  \n",
       "5   0.751407   0.580930  0.727831  \n",
       "9   0.452648   0.922374  0.725230  \n",
       "6   0.323741   0.986346  0.680505  \n",
       "0   0.271494   0.939592  0.649895  \n",
       "3   0.256280   0.943962  0.643806  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
